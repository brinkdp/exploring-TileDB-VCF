{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1185f2cf-66f4-403b-86ad-779fe74fbcf3",
   "metadata": {},
   "source": [
    "# Exploring TileDB-VCF: \n",
    "# Notebook 1. Initiation and general operations\n",
    "2024-12-13 Daniel P. Brink\n",
    "\n",
    "This is a notebook for getting familiar with the TileDB-VCF python library.\n",
    "\n",
    "A large chunk of the commands are based on following this [tutorial](https://tiledb-inc.github.io/TileDB-VCF/examples/tutorial_tiledbvcf_basics.html)\n",
    "\n",
    "Other resources:\n",
    "- VCF format specification [URL](https://en.wikipedia.org/wiki/Variant_Call_Format)\n",
    "\n",
    "- The original paper on vcftools and the VCF file format [URL](https://doi.org/10.1093/bioinformatics/btr330)\n",
    "\n",
    "# Contents\n",
    "- [1. Installation and initiation](#1-installation-and-initiation)\n",
    "- [2. Ingestion of data](#2-ingestion-of-data)\n",
    "- [3. Queries based on metadata](#3-queries-based-on-metadata)\n",
    "- [4. Export a TileDB-VCF dataset instance to VCF](#4-Export-a-TileDB-VCF-dataset-instance-to-VCF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac959dd-ce7c-41e7-a04a-8a491375df72",
   "metadata": {},
   "source": [
    "# 1. Installation and initiation\n",
    "\n",
    "Installed TileDB-VCF and other dependencies used in this notebook with conda on a Mac M3:\n",
    "```\n",
    "CONDA_SUBDIR=osx-64 conda create -n tileDB_vcf \n",
    "conda activate tileDB_vcf\n",
    "conda install mamba -y\n",
    "mamba install -c conda-forge libgoogle-cloud=2.26 -y\n",
    "mamba install -c conda-forge -c bioconda -c tiledb tiledbvcf-py -y\n",
    "mamba install -c conda-forge -c bioconda -c tiledb libtiledbvcf -y\n",
    "mamba install jupyter -y\n",
    "mamba install bcftools -y\n",
    "```\n",
    "\n",
    "The `mamba install -c conda-forge libgoogle-cloud=2.26 -y`line was an attempt to circumvent the error, as discussed on the [official forums](https://forum.tiledb.com/t/tiledbvcf-installation-error-on-macos/710) but it did not work on my computer. As is discussed below, this seemed to not be necessary since the error seemed to come from not having loaded all necessary libraries. However, for the sake of reproducibility, the full installation parameters for the conda environment were included above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f00bd86f-ca63-4efd-bcad-81f2b2ccf988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Conda environment: tileDB_vcf\n",
      "tiledb v0.31.1\n",
      "numpy v1.26.4\n",
      "tiledb-vcf v0.34.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tiledb\n",
    "import tiledbvcf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "#Check that Conda and the libraries are installed as expected:\n",
    "print(f\"Current Conda environment: {os.environ['CONDA_DEFAULT_ENV']}\")\n",
    "\n",
    "print(\n",
    "    f\"tiledb v{tiledb.version.version}\\n\"\n",
    "    f\"numpy v{np.__version__}\\n\"\n",
    "    f\"tiledb-vcf v{tiledbvcf.version}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac5029a-6d66-4b7c-9d55-ec2024d952e3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Note! In the official installation documentation for [the TileDB-VCF python package](https://docs.tiledb.com/main/integrations-and-extensions/genomics/population-genomics/installation/quick-install) , it is suggested to run this command in the terminal to verify the install: `python -c \"import tiledbvcf; print(tiledbvcf.version)\"`. However, as the above code blocks shows, the import works if the tiledb python library is also imported. The corrected command for a user that focuses on tiledbvcf is: `python -c \"import tiledb, tiledbvcf; print(tiledbvcf.version)\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae43775-ee77-4edd-9e2a-9f7b030ef1bf",
   "metadata": {},
   "source": [
    "The next step is to setup TileDB’s virtual file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b0d7d1c-a3f8-409b-b59a-f26cc0948161",
   "metadata": {},
   "outputs": [],
   "source": [
    "vfs = tiledb.VFS(config=tiledb.Config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad6337a-0408-4afc-9392-96e7eeec52f2",
   "metadata": {},
   "source": [
    "# 2. Ingestion of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782eb45e-8ae0-432b-ba81-4d3322695b7c",
   "metadata": {},
   "source": [
    "Initiate a temp TileDB array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7748d527-b39c-440c-94f6-d5f15fd5c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_uri = \"./temp_array_storage/demo-arraylocal\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f301057-8cfe-48b7-a351-700868f1a6d1",
   "metadata": {},
   "source": [
    "Check if this array exists from before. If yes, delete the existing array to start fresh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ae57ffee-75d6-4d01-9b67-0aa8b4eef37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (vfs.is_dir(array_uri)):\n",
    "    print(f\"Deleting existing array '{array_uri}'\")\n",
    "    vfs.remove_dir(array_uri)\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef91cec-cb82-4cb3-a794-24d1953b7905",
   "metadata": {},
   "source": [
    "Fetch tutorial data from cloud storage. Create a list of URIs pointing to 5 sample BCF files from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6c1a5d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s3://tiledb-inc-demo-data/examples/notebooks/vcfs/1kgp3-chr1/HG00096.bcf',\n",
       " 's3://tiledb-inc-demo-data/examples/notebooks/vcfs/1kgp3-chr1/HG00097.bcf',\n",
       " 's3://tiledb-inc-demo-data/examples/notebooks/vcfs/1kgp3-chr1/HG00099.bcf',\n",
       " 's3://tiledb-inc-demo-data/examples/notebooks/vcfs/1kgp3-chr1/HG00100.bcf',\n",
       " 's3://tiledb-inc-demo-data/examples/notebooks/vcfs/1kgp3-chr1/HG00101.bcf']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_bucket = \"s3://tiledb-inc-demo-data/examples/notebooks/vcfs/1kgp3-chr1\"\n",
    "batch1_samples = [\"HG00096.bcf\", \"HG00097.bcf\", \"HG00099.bcf\", \"HG00100.bcf\", \"HG00101.bcf\"]\n",
    "batch1_uris = [f\"{vcf_bucket}/{s}\" for s in batch1_samples]\n",
    "batch1_uris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3303e88b",
   "metadata": {},
   "source": [
    "Create a TileDB-VCF Dataset instance that opens a connection to our desired array_uri in write mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "70e95d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__meta',\n",
       " 'variant_stats',\n",
       " 'allele_count',\n",
       " 'sample_stats',\n",
       " 'data',\n",
       " '__tiledb_group.tdb',\n",
       " 'metadata',\n",
       " '__group']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tiledbvcf.Dataset(uri=array_uri, mode=\"w\")\n",
    "ds\n",
    "ds.create_dataset(vcf_attrs=batch1_uris[0], enable_allele_count=True, enable_variant_stats=True)\n",
    "\n",
    "# Verify that the array exists\n",
    "os.listdir(array_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48683521",
   "metadata": {},
   "source": [
    "An error message here can imply that the dataset already exists and cannot be overwritten. The if statement above can be run to overcome this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dbd429",
   "metadata": {},
   "source": [
    "The dataset instance has now been created, but it does not contain any data yet. The ingest_sample function needs to be run to populate the instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5c9da79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 4.27 s, total: 19.6 s\n",
      "Wall time: 2min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.ingest_samples(sample_uris = batch1_uris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70b8027",
   "metadata": {},
   "source": [
    "This tutorial data is fetched from a S3 cloud. It is likely that a majority of the time required to ingest the data comes from making the remote connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9bb8ee",
   "metadata": {},
   "source": [
    "Ingest a second list of samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dab8ea3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 4.12 s, total: 19.3 s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "batch2_samples = [\"HG00102.bcf\", \"HG00103.bcf\", \"HG00105.bcf\", \"HG00106.bcf\", \"HG00107.bcf\"]\n",
    "batch2_uris = [f\"{vcf_bucket}/{s}\" for s in batch2_samples]\n",
    "batch2_uris\n",
    "\n",
    "ds = tiledbvcf.Dataset(uri=array_uri, mode=\"w\") #Incremental update to the array, previous data is not touched \n",
    "ds.ingest_samples(sample_uris = batch2_uris)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21905f6d",
   "metadata": {},
   "source": [
    "Verify the ingestion by opening the array in read mode and printing out the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7518f7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HG00096',\n",
       " 'HG00097',\n",
       " 'HG00099',\n",
       " 'HG00100',\n",
       " 'HG00101',\n",
       " 'HG00102',\n",
       " 'HG00103',\n",
       " 'HG00105',\n",
       " 'HG00106',\n",
       " 'HG00107']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tiledbvcf.Dataset(array_uri, mode = \"r\")\n",
    "ds.samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa0889",
   "metadata": {},
   "source": [
    "So what is the ds object? It is a tiledbvcf.dataset.Dataset, as shown by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c00e5237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tiledbvcf.dataset.Dataset"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f950d1",
   "metadata": {},
   "source": [
    "The docstring for the `ds` object is through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cf103c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Dataset in module tiledbvcf.dataset object:\n",
      "\n",
      "class Dataset(builtins.object)\n",
      " |  Dataset(uri: str, mode: str = 'r', cfg: tiledbvcf.dataset.ReadConfig = None, stats: bool = False, verbose: bool = False, tiledb_config: dict = None)\n",
      " |\n",
      " |  A class that provides read/write access to a TileDB-VCF dataset.\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  uri\n",
      " |      URI of the dataset.\n",
      " |  mode\n",
      " |      Mode of operation ('r'|'w')\n",
      " |  cfg\n",
      " |      TileDB-VCF configuration.\n",
      " |  stats\n",
      " |      Enable internal TileDB statistics.\n",
      " |  verbose\n",
      " |      Enable verbose output.\n",
      " |  tiledb_config\n",
      " |      TileDB configuration, alternative to `cfg.tiledb_config`.\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, uri: str, mode: str = 'r', cfg: tiledbvcf.dataset.ReadConfig = None, stats: bool = False, verbose: bool = False, tiledb_config: dict = None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  attributes(self, attr_type='all') -> list\n",
      " |      Return a list of queryable attributes available in the VCF dataset.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      attr_type : str\n",
      " |          The subset of attributes to retrieve; \"info\" or \"fmt\" will\n",
      " |          only retrieve attributes ingested from the VCF INFO and\n",
      " |          FORMAT fields, respectively, \"builtin\" retrieves the static\n",
      " |          attributes defined in TileDB-VCF's schema, \"all\" (the\n",
      " |          default) returns all queryable attributes.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :\n",
      " |          A list of attribute names.\n",
      " |\n",
      " |  continue_read(self, release_buffers: bool = True) -> pandas.core.frame.DataFrame\n",
      " |      Continue an incomplete read.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      release_buffers\n",
      " |          Release the buffers after reading.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :\n",
      " |          The next batch of data as a Pandas DataFrame.\n",
      " |\n",
      " |  continue_read_arrow(self, release_buffers: bool = True) -> pyarrow.lib.Table\n",
      " |      Continue an incomplete read.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      release_buffers\n",
      " |          Release the buffers after reading.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :\n",
      " |          The next batch of data as a PyArrow Table.\n",
      " |\n",
      " |  count(self, samples: (<class 'str'>, typing.List[str]) = None, regions: (<class 'str'>, typing.List[str]) = None) -> int\n",
      " |      Count records in the dataset.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      samples\n",
      " |          Sample names to include in the count.\n",
      " |      regions\n",
      " |          Genomic regions to include in the count.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :\n",
      " |          Number of intersecting records in the dataset.\n",
      " |\n",
      " |  create_dataset(self, extra_attrs: str = None, vcf_attrs: str = None, tile_capacity: int = 10000, anchor_gap: int = 1000, checksum_type: str = 'sha256', allow_duplicates: bool = True, enable_allele_count: bool = True, enable_variant_stats: bool = True, enable_sample_stats: bool = True, compress_sample_dim: bool = True, compression_level: int = 4, variant_stats_version: int = 2)\n",
      " |      Create a new dataset.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      extra_attrs\n",
      " |          CSV list of extra attributes to materialize from fmt and info fields.\n",
      " |      vcf_attrs\n",
      " |          URI of VCF file with all fmt and info fields to materialize in the dataset.\n",
      " |      tile_capacity\n",
      " |          Tile capacity to use for the array schema.\n",
      " |      anchor_gap\n",
      " |          Length of gaps between inserted anchor records in bases.\n",
      " |      checksum_type\n",
      " |          Optional checksum type for the dataset, \"sha256\" or \"md5\".\n",
      " |      allow_duplicates\n",
      " |          Allow records with duplicate start positions to be written to the array.\n",
      " |      enable_allele_count\n",
      " |          Enable the allele count ingestion task.\n",
      " |      enable_variant_stats\n",
      " |          Enable the variant stats ingestion task.\n",
      " |      enable_sample_stats\n",
      " |          Enable the sample stats ingestion task.\n",
      " |      compress_sample_dim\n",
      " |          Enable compression on the sample dimension.\n",
      " |      compression_level\n",
      " |          Compression level for zstd compression.\n",
      " |      variant_stats_version\n",
      " |          Version of the variant stats array.\n",
      " |\n",
      " |  export(self, samples: (<class 'str'>, typing.List[str]) = None, regions: (<class 'str'>, typing.List[str]) = None, samples_file: str = None, bed_file: str = None, skip_check_samples: bool = False, enable_progress_estimation: bool = False, merge: bool = False, output_format: str = 'z', output_path: str = '', output_dir: str = '.')\n",
      " |      Exports data to multiple VCF files or a combined VCF file.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      samples\n",
      " |          Sample names to be read.\n",
      " |      regions\n",
      " |          Genomic regions to be read.\n",
      " |      samples_file\n",
      " |          URI of file containing sample names to be read, one per line.\n",
      " |      bed_file\n",
      " |          URI of a BED file of genomic regions to be read.\n",
      " |      skip_check_samples\n",
      " |          Skip checking if the samples in `samples_file` exist in the dataset.\n",
      " |      set_af_filter\n",
      " |          Filter variants by internal allele frequency. For example, to include\n",
      " |          variants with AF > 0.1, set this to \">0.1\".\n",
      " |      scan_all_samples\n",
      " |          Scan all samples when computing internal allele frequency.\n",
      " |      enable_progress_estimation\n",
      " |          **DEPRECATED** - This parameter will be removed in a future release.\n",
      " |      merge\n",
      " |          Merge samples to create a combined VCF file.\n",
      " |      output_format\n",
      " |          Export file format: 'b': bcf (compressed), 'u': bcf, 'z':vcf.gz, 'v': vcf.\n",
      " |      output_path\n",
      " |          Combined VCF output file.\n",
      " |      output_dir\n",
      " |          Directory used for local output of exported samples.\n",
      " |\n",
      " |  ingest_samples(self, sample_uris: List[str] = None, threads: int = None, total_memory_budget_mb: int = None, total_memory_percentage: float = None, ratio_tiledb_memory: float = None, max_tiledb_memory_mb: int = None, input_record_buffer_mb: int = None, avg_vcf_record_size: int = None, ratio_task_size: float = None, ratio_output_flush: float = None, scratch_space_path: str = None, scratch_space_size: int = None, sample_batch_size: int = None, resume: bool = False, contig_fragment_merging: bool = True, contigs_to_keep_separate: List[str] = None, contigs_to_allow_merging: List[str] = None, contig_mode: str = 'all', thread_task_size: int = None, memory_budget_mb: int = None, record_limit: int = None)\n",
      " |      Ingest VCF files into the dataset.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      sample_uris\n",
      " |          List of sample URIs to ingest.\n",
      " |      threads\n",
      " |          Set the number of threads used for ingestion.\n",
      " |      total_memory_budget_mb\n",
      " |          Total memory budget for ingestion (MiB).\n",
      " |      total_memory_percentage\n",
      " |          Percentage of total system memory used for ingestion\n",
      " |          (overrides 'total_memory_budget_mb').\n",
      " |      ratio_tiledb_memory\n",
      " |          Ratio of memory budget allocated to `TileDB::sm.mem.total_budget`.\n",
      " |      max_tiledb_memory_mb\n",
      " |          Maximum memory allocated to TileDB::sm.mem.total_budget (MiB).\n",
      " |      input_record_buffer_mb\n",
      " |          Size of input record buffer for each sample file (MiB).\n",
      " |      avg_vcf_record_size\n",
      " |          Average VCF record size (bytes).\n",
      " |      ratio_task_size\n",
      " |          Ratio of worker task size to computed task size.\n",
      " |      ratio_output_flush\n",
      " |          Ratio of output buffer capacity that triggers a flush to TileDB.\n",
      " |      scratch_space_path\n",
      " |          Directory used for local storage of downloaded remote samples.\n",
      " |      scratch_space_size\n",
      " |          Amount of local storage that can be used for downloading\n",
      " |          remote samples (MB).\n",
      " |      sample_batch_size\n",
      " |          Number of samples per batch for ingestion (default 10).\n",
      " |      resume\n",
      " |          Whether to check and attempt to resume a partial completed ingestion.\n",
      " |      contig_fragment_merging\n",
      " |          Whether to enable merging of contigs into fragments. This\n",
      " |          overrides the contigs-to-keep-separate/contigs-to-allow-\n",
      " |          merging options. Generally contig fragment merging is good,\n",
      " |          this is a performance optimization to reduce the prefixes on\n",
      " |          a s3/azure/gcs bucket when there is a large number of pseudo\n",
      " |          contigs which are small in size.\n",
      " |      contigs_to_keep_separate\n",
      " |          List of contigs that should not be merged into combined\n",
      " |          fragments. The default list includes all standard human\n",
      " |          chromosomes in both UCSC (e.g., chr1) and Ensembl (e.g., 1)\n",
      " |          formats.\n",
      " |      contigs_to_allow_merging\n",
      " |          List of contigs that should be allowed to be merged into\n",
      " |          combined fragments.\n",
      " |      contig_mode\n",
      " |          Select which contigs are ingested: 'all', 'separate', or 'merged'.\n",
      " |      thread_task_size\n",
      " |          **DEPRECATED** - This parameter will be removed in a future release.\n",
      " |      memory_budget_mb\n",
      " |          **DEPRECATED** - This parameter will be removed in a future release.\n",
      " |      record_limit\n",
      " |          **DEPRECATED** - This parameter will be removed in a future release.\n",
      " |\n",
      " |  map_dask(self, *args, **kwargs)\n",
      " |      Maps a function on a Dask dataframe obtained by reading from the dataset.\n",
      " |\n",
      " |      May be more efficient in some cases than read_dask() followed by a regular\n",
      " |      Dask map operation.\n",
      " |\n",
      " |      The remaining parameters are the same as the read_dask() function.\n",
      " |\n",
      " |      :return: Dask DataFrame with results\n",
      " |\n",
      " |  read(self, attrs: List[str] = ['sample_name', 'contig', 'pos_start', 'alleles', 'fmt_GT'], samples: (<class 'str'>, typing.List[str]) = None, regions: (<class 'str'>, typing.List[str]) = None, samples_file: str = None, bed_file: str = None, skip_check_samples: bool = False, set_af_filter: str = '', scan_all_samples: bool = False, enable_progress_estimation: bool = False) -> pandas.core.frame.DataFrame\n",
      " |      Read data from the dataset into a Pandas DataFrame.\n",
      " |\n",
      " |      For large datasets, a call to `read()` may not be able to fit all\n",
      " |      results in memory. In that case, the returned table will contain as\n",
      " |      many results as possible, and in order to retrieve the rest of the\n",
      " |      results, use the `continue_read()` function.\n",
      " |\n",
      " |      You can also use the Python generator version, `read_iter()`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      attrs\n",
      " |          List of attribute names to be read.\n",
      " |      samples\n",
      " |          Sample names to be read.\n",
      " |      regions\n",
      " |          Genomic regions to be read.\n",
      " |      samples_file\n",
      " |          URI of file containing sample names to be read, one per line.\n",
      " |      bed_file\n",
      " |          URI of a BED file of genomic regions to be read.\n",
      " |      skip_check_samples\n",
      " |          Skip checking if the samples in `samples_file` exist in the dataset.\n",
      " |      set_af_filter\n",
      " |          Filter variants by internal allele frequency. For example, to include\n",
      " |          variants with AF > 0.1, set this to \">0.1\".\n",
      " |      enable_progress_estimation\n",
      " |          **DEPRECATED** - This parameter will be removed in a future release.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :\n",
      " |          Query results as a Pandas DataFrame.\n",
      " |\n",
      " |  read_allele_count(self, region: str = None) -> pandas.core.frame.DataFrame\n",
      " |      Read allele count from the dataset into a Pandas DataFrame\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      region\n",
      " |          Genomic region to be queried.\n",
      " |\n",
      " |  read_arrow(self, attrs: List[str] = ['sample_name', 'contig', 'pos_start', 'alleles', 'fmt_GT'], samples: (<class 'str'>, typing.List[str]) = None, regions: (<class 'str'>, typing.List[str]) = None, samples_file: str = None, bed_file: str = None, skip_check_samples: bool = False, set_af_filter: str = '', scan_all_samples: bool = False, enable_progress_estimation: bool = False) -> pyarrow.lib.Table\n",
      " |      Read data from the dataset into a PyArrow Table.\n",
      " |\n",
      " |      For large queries, a call to `read_arrow()` may not be able to fit all\n",
      " |      results in memory. In that case, the returned table will contain as\n",
      " |      many results as possible, and in order to retrieve the rest of the\n",
      " |      results, use the `continue_read()` function.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      attrs\n",
      " |          List of attribute names to be read.\n",
      " |      samples\n",
      " |          Sample names to be read.\n",
      " |      regions\n",
      " |          Genomic regions to be read.\n",
      " |      samples_file\n",
      " |          URI of file containing sample names to be read, one per line.\n",
      " |      bed_file\n",
      " |          URI of a BED file of genomic regions to be read.\n",
      " |      skip_check_samples\n",
      " |          Skip checking if the samples in `samples_file` exist in the dataset.\n",
      " |      set_af_filter\n",
      " |          Filter variants by internal allele frequency. For example, to include\n",
      " |          variants with AF > 0.1, set this to \">0.1\".\n",
      " |      scan_all_samples\n",
      " |          Scan all samples when computing internal allele frequency.\n",
      " |      enable_progress_estimation\n",
      " |          **DEPRECATED** - This parameter will be removed in a future release.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :\n",
      " |          Query results as a PyArrow Table.\n",
      " |\n",
      " |  read_completed(self) -> bool\n",
      " |      Returns true if the previous read operation was complete.\n",
      " |      A read is considered complete if the resulting dataframe contained\n",
      " |      all results.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |          True if the previous read operation was complete.\n",
      " |\n",
      " |  read_dask(self, *args, **kwargs)\n",
      " |      Reads data from a TileDB-VCF into a Dask DataFrame.\n",
      " |\n",
      " |      Partitioning proceeds by a straightforward block distribution, parameterized\n",
      " |      by the total number of partitions and the particular partition index that\n",
      " |      a particular read operation is responsible for.\n",
      " |\n",
      " |      Both region and sample partitioning can be used together.\n",
      " |\n",
      " |      The remaining parameters are the same as the normal read() function.\n",
      " |\n",
      " |      :param int region_partition: Number of partitions over regions\n",
      " |      :param int sample_partition: Number of partitions over samples\n",
      " |      :param int limit_partitions: Maximum number of partitions to read (for testing/debugging)\n",
      " |\n",
      " |      :return: Dask DataFrame with results\n",
      " |\n",
      " |  read_iter(self, attrs: List[str] = ['sample_name', 'contig', 'pos_start', 'alleles', 'fmt_GT'], samples: (<class 'str'>, typing.List[str]) = None, regions: (<class 'str'>, typing.List[str]) = None, samples_file: str = None, bed_file: str = None)\n",
      " |      Iterator version of `read()`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      attrs\n",
      " |          List of attribute names to be read.\n",
      " |      samples\n",
      " |          Sample names to be read.\n",
      " |      regions\n",
      " |          Genomic regions to be read.\n",
      " |      samples_file\n",
      " |          URI of file containing sample names to be read, one per line.\n",
      " |      bed_file\n",
      " |          URI of a BED file of genomic regions to be read.\n",
      " |\n",
      " |  read_variant_stats(self, region: str = None) -> pandas.core.frame.DataFrame\n",
      " |      Read variant stats from the dataset into a Pandas DataFrame\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      region\n",
      " |          Genomic region to be queried.\n",
      " |\n",
      " |  sample_count(self) -> int\n",
      " |      Get the number of samples in the dataset.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :\n",
      " |          Number of samples in the dataset.\n",
      " |\n",
      " |  samples(self) -> list\n",
      " |      Get the list of samples in the dataset.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :\n",
      " |          List of samples in the dataset.\n",
      " |\n",
      " |  schema_version(self) -> int\n",
      " |      Get the VCF schema version of the dataset.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :\n",
      " |          VCF schema version of the dataset.\n",
      " |\n",
      " |  tiledb_stats(self) -> str\n",
      " |      Get TileDB stats as a string.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :\n",
      " |          TileDB stats as a string.\n",
      " |\n",
      " |  version(self) -> str\n",
      " |      Return the TileDB-VCF version used to create the dataset.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      :\n",
      " |          The TileDB-VCF version.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d3a7a6",
   "metadata": {},
   "source": [
    "Some imporant methods of the `ds` object are:\n",
    "\n",
    "`ds.ingest_samples()`\n",
    "\n",
    "`ds.samples()`\n",
    "\n",
    "`ds.read()`\n",
    "\n",
    "`ds.export()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2d7402",
   "metadata": {},
   "source": [
    "We have already seen in the above examples how `ds.ingest_samples` can be used iteratively to add new samples to the dataset instance, and how `ds.samples()` can be used to display all samples in the dataset. Queries with `ds.read()` will be investigated below and in section 3. In section 4, `ds.export` will be used to export the TileDB array to VCF files.\n",
    "\n",
    "Queries to the instance is done with the `ds.read` command. The output is a pandas dataframe. There are also functions to read the data to a pyarrow table or a Dask dataframe. But let's stick with `ds.read` for now.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8f689172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 ms, sys: 57.3 ms, total: 93.4 ms\n",
      "Wall time: 113 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>contig</th>\n",
       "      <th>pos_start</th>\n",
       "      <th>pos_end</th>\n",
       "      <th>fmt_GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11107439</td>\n",
       "      <td>11107439</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11111976</td>\n",
       "      <td>11111979</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11112836</td>\n",
       "      <td>11112836</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11115299</td>\n",
       "      <td>11115299</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11117536</td>\n",
       "      <td>11117536</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11254006</td>\n",
       "      <td>11254007</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11260848</td>\n",
       "      <td>11260848</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11261929</td>\n",
       "      <td>11261929</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11262020</td>\n",
       "      <td>11262020</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11262310</td>\n",
       "      <td>11262310</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_name contig  pos_start   pos_end  fmt_GT\n",
       "0       HG00096      1   11107439  11107439  [1, 1]\n",
       "1       HG00096      1   11111976  11111979  [0, 1]\n",
       "2       HG00096      1   11112836  11112836  [0, 1]\n",
       "3       HG00096      1   11115299  11115299  [0, 1]\n",
       "4       HG00096      1   11117536  11117536  [0, 1]\n",
       "..          ...    ...        ...       ...     ...\n",
       "119     HG00096      1   11254006  11254007  [0, 1]\n",
       "120     HG00096      1   11260848  11260848  [0, 1]\n",
       "121     HG00096      1   11261929  11261929  [0, 1]\n",
       "122     HG00096      1   11262020  11262020  [0, 1]\n",
       "123     HG00096      1   11262310  11262310  [0, 1]\n",
       "\n",
       "[124 rows x 5 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "regions = [\"1:11106535-11262551\"]\n",
    "samples= [\"HG00096\"]\n",
    "attributes = [\"sample_name\", \"contig\", \"pos_start\", \"pos_end\", \"fmt_GT\"]\n",
    "\n",
    "df = ds.read(\n",
    "    regions = regions,\n",
    "    samples = samples,\n",
    "    attrs = attributes,\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c90dc9b",
   "metadata": {},
   "source": [
    "Another attribute that can be included is the Allele Frequency Field (`info_TILEDB_IAF`): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cd38e621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.3 ms, sys: 67.4 ms, total: 119 ms\n",
      "Wall time: 111 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>contig</th>\n",
       "      <th>pos_start</th>\n",
       "      <th>pos_end</th>\n",
       "      <th>fmt_GT</th>\n",
       "      <th>info_TILEDB_IAF</th>\n",
       "      <th>alleles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11107439</td>\n",
       "      <td>11107439</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[G, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00097</td>\n",
       "      <td>1</td>\n",
       "      <td>11107439</td>\n",
       "      <td>11107439</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "      <td>[G, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11111976</td>\n",
       "      <td>11111979</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.05, 0.95]</td>\n",
       "      <td>[TGAA, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00097</td>\n",
       "      <td>1</td>\n",
       "      <td>11111976</td>\n",
       "      <td>11111979</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.05, 0.95]</td>\n",
       "      <td>[TGAA, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11112836</td>\n",
       "      <td>11112836</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.05, 0.95]</td>\n",
       "      <td>[T, C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>HG00097</td>\n",
       "      <td>1</td>\n",
       "      <td>11261929</td>\n",
       "      <td>11261929</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.1, 0.9]</td>\n",
       "      <td>[T, C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11262020</td>\n",
       "      <td>11262020</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.1, 0.9]</td>\n",
       "      <td>[A, G]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>HG00097</td>\n",
       "      <td>1</td>\n",
       "      <td>11262020</td>\n",
       "      <td>11262020</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.1, 0.9]</td>\n",
       "      <td>[A, G]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11262310</td>\n",
       "      <td>11262310</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.1, 0.9]</td>\n",
       "      <td>[T, C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>HG00097</td>\n",
       "      <td>1</td>\n",
       "      <td>11262310</td>\n",
       "      <td>11262310</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.1, 0.9]</td>\n",
       "      <td>[T, C]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_name contig  pos_start   pos_end  fmt_GT info_TILEDB_IAF    alleles\n",
       "0       HG00096      1   11107439  11107439  [1, 1]      [0.0, 1.0]     [G, T]\n",
       "1       HG00097      1   11107439  11107439  [1, 1]      [0.0, 1.0]     [G, T]\n",
       "2       HG00096      1   11111976  11111979  [0, 1]    [0.05, 0.95]  [TGAA, T]\n",
       "3       HG00097      1   11111976  11111979  [1, 1]    [0.05, 0.95]  [TGAA, T]\n",
       "4       HG00096      1   11112836  11112836  [0, 1]    [0.05, 0.95]     [T, C]\n",
       "..          ...    ...        ...       ...     ...             ...        ...\n",
       "232     HG00097      1   11261929  11261929  [1, 1]      [0.1, 0.9]     [T, C]\n",
       "233     HG00096      1   11262020  11262020  [0, 1]      [0.1, 0.9]     [A, G]\n",
       "234     HG00097      1   11262020  11262020  [1, 1]      [0.1, 0.9]     [A, G]\n",
       "235     HG00096      1   11262310  11262310  [0, 1]      [0.1, 0.9]     [T, C]\n",
       "236     HG00097      1   11262310  11262310  [1, 1]      [0.1, 0.9]     [T, C]\n",
       "\n",
       "[237 rows x 7 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "regions = [\"1:11106535-11262551\"]\n",
    "samples = [\"HG00096\",\"HG00097\"]\n",
    "attributes = [\"sample_name\", \"contig\", \"pos_start\", \"pos_end\", \"fmt_GT\", \"info_TILEDB_IAF\"]\n",
    "\n",
    "df = ds.read(\n",
    "    regions = regions,\n",
    "    samples = samples,\n",
    "    attrs = attributes,\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f3b90",
   "metadata": {},
   "source": [
    "Allele frequencies can futher be filtered directly in the query with the `set_af_filter` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3b4ab93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>contig</th>\n",
       "      <th>pos_start</th>\n",
       "      <th>pos_end</th>\n",
       "      <th>fmt_GT</th>\n",
       "      <th>info_TILEDB_IAF</th>\n",
       "      <th>alleles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11111976</td>\n",
       "      <td>11111979</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.05, 0.95]</td>\n",
       "      <td>[TGAA, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11112836</td>\n",
       "      <td>11112836</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.05, 0.95]</td>\n",
       "      <td>[T, C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11117536</td>\n",
       "      <td>11117536</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.05, 0.95]</td>\n",
       "      <td>[A, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11118390</td>\n",
       "      <td>11118390</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.05, 0.95]</td>\n",
       "      <td>[G, A]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11119135</td>\n",
       "      <td>11119135</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.05, 0.95]</td>\n",
       "      <td>[G, A]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11252805</td>\n",
       "      <td>11252806</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.05, 0.95]</td>\n",
       "      <td>[TA, T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11254006</td>\n",
       "      <td>11254007</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.1, 0.9]</td>\n",
       "      <td>[AC, A]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11261929</td>\n",
       "      <td>11261929</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.1, 0.9]</td>\n",
       "      <td>[T, C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11262020</td>\n",
       "      <td>11262020</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.1, 0.9]</td>\n",
       "      <td>[A, G]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>HG00096</td>\n",
       "      <td>1</td>\n",
       "      <td>11262310</td>\n",
       "      <td>11262310</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.1, 0.9]</td>\n",
       "      <td>[T, C]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_name contig  pos_start   pos_end  fmt_GT info_TILEDB_IAF    alleles\n",
       "0      HG00096      1   11111976  11111979  [0, 1]    [0.05, 0.95]  [TGAA, T]\n",
       "1      HG00096      1   11112836  11112836  [0, 1]    [0.05, 0.95]     [T, C]\n",
       "2      HG00096      1   11117536  11117536  [0, 1]    [0.05, 0.95]     [A, T]\n",
       "3      HG00096      1   11118390  11118390  [0, 1]    [0.05, 0.95]     [G, A]\n",
       "4      HG00096      1   11119135  11119135  [0, 1]    [0.05, 0.95]     [G, A]\n",
       "..         ...    ...        ...       ...     ...             ...        ...\n",
       "82     HG00096      1   11252805  11252806  [0, 1]    [0.05, 0.95]    [TA, T]\n",
       "83     HG00096      1   11254006  11254007  [0, 1]      [0.1, 0.9]    [AC, A]\n",
       "84     HG00096      1   11261929  11261929  [0, 1]      [0.1, 0.9]     [T, C]\n",
       "85     HG00096      1   11262020  11262020  [0, 1]      [0.1, 0.9]     [A, G]\n",
       "86     HG00096      1   11262310  11262310  [0, 1]      [0.1, 0.9]     [T, C]\n",
       "\n",
       "[87 rows x 7 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds.read(\n",
    "    regions = regions,\n",
    "    samples = samples,\n",
    "    attrs = attributes,\n",
    "    set_af_filter=\"<0.5\",\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fff5d3",
   "metadata": {},
   "source": [
    "# 3. Queries based on metadata\n",
    "\n",
    "Metadata-based queries are supported by TileDB-VCF. Documentation can be found in this tutorial:\n",
    "https://documentation.cloud.tiledb.com/academy/structure/life-sciences/population-genomics/tutorials/advanced/sample-metadata/\n",
    "\n",
    "This tutorial is based on having access to a dataset on tileDB cloud, which requires a licence. But for testing the code, we can actually use any dataset and make mock metadata for it\n",
    "\n",
    "First, reinitalize the ds object to avoid buffer errors related to the allele filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5c0b79a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HG00096',\n",
       " 'HG00097',\n",
       " 'HG00099',\n",
       " 'HG00100',\n",
       " 'HG00101',\n",
       " 'HG00102',\n",
       " 'HG00103',\n",
       " 'HG00105',\n",
       " 'HG00106',\n",
       " 'HG00107']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = tiledbvcf.Dataset(array_uri, mode = \"r\")\n",
    "ds.samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64768c54",
   "metadata": {},
   "source": [
    "Slice out the last four samples from the pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d877bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HG00103', 'HG00105', 'HG00106', 'HG00107']\n"
     ]
    }
   ],
   "source": [
    "query_samples = ds.samples()[-4:]\n",
    "print(query_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462a4be0",
   "metadata": {},
   "source": [
    "Create mock metadata fields for the dataset. Run it through a function from the tutorial to convert the metadata dataframe to a TileDB array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5c094f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array already exists, refreshing.\n"
     ]
    }
   ],
   "source": [
    "metadata_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Sample\": query_samples,\n",
    "        \"Parent\": [\"X400\", \"X400\", \"X301\", \"X203\"], \n",
    "        \"Weight\": [45, 23, 11, 57], \n",
    "        \"PureBreed\": [True, True, False, True],\n",
    "    },\n",
    ")\n",
    "\n",
    "metadata_uri = \"temp_array_storage/mock_metadata_array\"\n",
    "\n",
    "def convert(metadata_df,metadata_uri):\n",
    "    \"\"\"Convert pandas.DataFrame to TileDB array.\n",
    "    \n",
    "    Delete array if it exists.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        tiledb.from_pandas(\n",
    "            metadata_uri, \n",
    "            metadata_df, \n",
    "            index_dims=[\"Sample\"],\n",
    "        )\n",
    "    except tiledb.TileDBError:\n",
    "        print(\"Array already exists, refreshing.\")\n",
    "        if os.path.exists(metadata_uri):\n",
    "            shutil.rmtree(metadata_uri)\n",
    "            \n",
    "        convert(metadata_df,metadata_uri)\n",
    "        \n",
    "convert(metadata_df,metadata_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4012ece8",
   "metadata": {},
   "source": [
    "We can view the schema of the resulting array with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "28cf403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArraySchema(\n",
      "  domain=Domain(*[\n",
      "    Dim(name='Sample', domain=('', ''), tile=None, dtype='|S0', var=True, filters=FilterList([ZstdFilter(level=-1), ])),\n",
      "  ]),\n",
      "  attrs=[\n",
      "    Attr(name='Parent', dtype='<U0', var=True, nullable=False, enum_label=None, filters=FilterList([ZstdFilter(level=-1), ])),\n",
      "    Attr(name='Weight', dtype='int64', var=False, nullable=False, enum_label=None, filters=FilterList([ZstdFilter(level=-1), ])),\n",
      "    Attr(name='PureBreed', dtype='bool', var=False, nullable=False, enum_label=None, filters=FilterList([ZstdFilter(level=-1), ])),\n",
      "  ],\n",
      "  cell_order='row-major',\n",
      "  tile_order='row-major',\n",
      "  capacity=10000,\n",
      "  sparse=True,\n",
      "  allows_duplicates=True,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tiledb.open(metadata_uri, \"r\") as Ar:\n",
    "    \n",
    "    print(Ar.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250da97",
   "metadata": {},
   "source": [
    "Now we can query the metadata array for all samples that contain patient \"X400\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e1393779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HG00103', 'HG00105']\n"
     ]
    }
   ],
   "source": [
    "# example parent we'd like to get samples for\n",
    "query_parent = \"X400\"\n",
    "\n",
    "with tiledb.open(metadata_uri, \"r\") as Ar:\n",
    "\n",
    "    # query metadata array for \n",
    "    sample_result = Ar.query(cond=f\"Parent == '{query_parent}'\")[:]\n",
    "\n",
    "samples = [s.decode() for s in sample_result[\"Sample\"]]\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a196bca4",
   "metadata": {},
   "source": [
    "Turns out that there were two samples that fulfilled this criterion. We can now pass this query result onwards to a query for the main dataset instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "65dd0d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>contig</th>\n",
       "      <th>pos_start</th>\n",
       "      <th>pos_end</th>\n",
       "      <th>alleles</th>\n",
       "      <th>fmt_GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG00103</td>\n",
       "      <td>1</td>\n",
       "      <td>10177</td>\n",
       "      <td>10177</td>\n",
       "      <td>[A, AC]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00105</td>\n",
       "      <td>1</td>\n",
       "      <td>10177</td>\n",
       "      <td>10177</td>\n",
       "      <td>[A, AC]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00103</td>\n",
       "      <td>1</td>\n",
       "      <td>10352</td>\n",
       "      <td>10352</td>\n",
       "      <td>[T, TA]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00103</td>\n",
       "      <td>1</td>\n",
       "      <td>10616</td>\n",
       "      <td>10637</td>\n",
       "      <td>[CCGCCGTTGCAAAGGCGCGCCG, C]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00105</td>\n",
       "      <td>1</td>\n",
       "      <td>10616</td>\n",
       "      <td>10637</td>\n",
       "      <td>[CCGCCGTTGCAAAGGCGCGCCG, C]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644002</th>\n",
       "      <td>HG00105</td>\n",
       "      <td>1</td>\n",
       "      <td>249240219</td>\n",
       "      <td>249240219</td>\n",
       "      <td>[A, T]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644003</th>\n",
       "      <td>HG00103</td>\n",
       "      <td>1</td>\n",
       "      <td>249240539</td>\n",
       "      <td>249240539</td>\n",
       "      <td>[T, G]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644004</th>\n",
       "      <td>HG00105</td>\n",
       "      <td>1</td>\n",
       "      <td>249240539</td>\n",
       "      <td>249240539</td>\n",
       "      <td>[T, G]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644005</th>\n",
       "      <td>HG00103</td>\n",
       "      <td>1</td>\n",
       "      <td>249240543</td>\n",
       "      <td>249240545</td>\n",
       "      <td>[AGG, A]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644006</th>\n",
       "      <td>HG00105</td>\n",
       "      <td>1</td>\n",
       "      <td>249240543</td>\n",
       "      <td>249240545</td>\n",
       "      <td>[AGG, A]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644007 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_name contig  pos_start    pos_end                      alleles  \\\n",
       "0          HG00103      1      10177      10177                      [A, AC]   \n",
       "1          HG00105      1      10177      10177                      [A, AC]   \n",
       "2          HG00103      1      10352      10352                      [T, TA]   \n",
       "3          HG00103      1      10616      10637  [CCGCCGTTGCAAAGGCGCGCCG, C]   \n",
       "4          HG00105      1      10616      10637  [CCGCCGTTGCAAAGGCGCGCCG, C]   \n",
       "...            ...    ...        ...        ...                          ...   \n",
       "644002     HG00105      1  249240219  249240219                       [A, T]   \n",
       "644003     HG00103      1  249240539  249240539                       [T, G]   \n",
       "644004     HG00105      1  249240539  249240539                       [T, G]   \n",
       "644005     HG00103      1  249240543  249240545                     [AGG, A]   \n",
       "644006     HG00105      1  249240543  249240545                     [AGG, A]   \n",
       "\n",
       "        fmt_GT  \n",
       "0       [1, 0]  \n",
       "1       [1, 0]  \n",
       "2       [1, 0]  \n",
       "3       [1, 1]  \n",
       "4       [1, 1]  \n",
       "...        ...  \n",
       "644002  [1, 0]  \n",
       "644003  [1, 0]  \n",
       "644004  [0, 1]  \n",
       "644005  [0, 1]  \n",
       "644006  [1, 0]  \n",
       "\n",
       "[644007 rows x 6 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "variant_results = ds.read(\n",
    "#    regions=[\"1:10177-249240219\"],\n",
    "    samples=samples,\n",
    "    attrs=[\n",
    "        \"sample_name\",\n",
    "        \"contig\",\n",
    "        \"pos_start\",\n",
    "        \"pos_end\",\n",
    "        \"alleles\",\n",
    "        \"fmt_GT\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "variant_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b0fd5",
   "metadata": {},
   "source": [
    "To demonstrate the work-flow in a denser presentation, we can put together it to a single code block. For fun, let's include all ten samples and not just the last four. This means that the metadata dataframe need to be updated with values for all samples. Down the line, this could be done by loading e.g. a tabular file, but for now, let's hard code this into the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2aea8d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array already exists, refreshing.\n",
      "['HG00102', 'HG00103', 'HG00105']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_name</th>\n",
       "      <th>contig</th>\n",
       "      <th>pos_start</th>\n",
       "      <th>pos_end</th>\n",
       "      <th>alleles</th>\n",
       "      <th>fmt_GT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HG00102</td>\n",
       "      <td>1</td>\n",
       "      <td>10177</td>\n",
       "      <td>10177</td>\n",
       "      <td>[A, AC]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HG00103</td>\n",
       "      <td>1</td>\n",
       "      <td>10177</td>\n",
       "      <td>10177</td>\n",
       "      <td>[A, AC]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HG00105</td>\n",
       "      <td>1</td>\n",
       "      <td>10177</td>\n",
       "      <td>10177</td>\n",
       "      <td>[A, AC]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HG00102</td>\n",
       "      <td>1</td>\n",
       "      <td>10352</td>\n",
       "      <td>10352</td>\n",
       "      <td>[T, TA]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HG00103</td>\n",
       "      <td>1</td>\n",
       "      <td>10352</td>\n",
       "      <td>10352</td>\n",
       "      <td>[T, TA]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966388</th>\n",
       "      <td>HG00103</td>\n",
       "      <td>1</td>\n",
       "      <td>249240539</td>\n",
       "      <td>249240539</td>\n",
       "      <td>[T, G]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966389</th>\n",
       "      <td>HG00105</td>\n",
       "      <td>1</td>\n",
       "      <td>249240539</td>\n",
       "      <td>249240539</td>\n",
       "      <td>[T, G]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966390</th>\n",
       "      <td>HG00102</td>\n",
       "      <td>1</td>\n",
       "      <td>249240543</td>\n",
       "      <td>249240545</td>\n",
       "      <td>[AGG, A]</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966391</th>\n",
       "      <td>HG00103</td>\n",
       "      <td>1</td>\n",
       "      <td>249240543</td>\n",
       "      <td>249240545</td>\n",
       "      <td>[AGG, A]</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966392</th>\n",
       "      <td>HG00105</td>\n",
       "      <td>1</td>\n",
       "      <td>249240543</td>\n",
       "      <td>249240545</td>\n",
       "      <td>[AGG, A]</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>966393 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_name contig  pos_start    pos_end   alleles  fmt_GT\n",
       "0          HG00102      1      10177      10177   [A, AC]  [1, 0]\n",
       "1          HG00103      1      10177      10177   [A, AC]  [1, 0]\n",
       "2          HG00105      1      10177      10177   [A, AC]  [1, 0]\n",
       "3          HG00102      1      10352      10352   [T, TA]  [1, 0]\n",
       "4          HG00103      1      10352      10352   [T, TA]  [1, 0]\n",
       "...            ...    ...        ...        ...       ...     ...\n",
       "966388     HG00103      1  249240539  249240539    [T, G]  [1, 0]\n",
       "966389     HG00105      1  249240539  249240539    [T, G]  [0, 1]\n",
       "966390     HG00102      1  249240543  249240545  [AGG, A]  [1, 1]\n",
       "966391     HG00103      1  249240543  249240545  [AGG, A]  [0, 1]\n",
       "966392     HG00105      1  249240543  249240545  [AGG, A]  [1, 0]\n",
       "\n",
       "[966393 rows x 6 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_samples = ds.samples()\n",
    "metadata_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Sample\": query_samples,\n",
    "        \"Parent\": [\"X200\",\"X200\",\"X205\",\"X206\",\"X115\",\"X400\",\"X400\",\"X400\", \"X301\", \"X203\"], \n",
    "        \"Weight\": [14, 23, 62, 31, 42, 19, 45, 23, 11, 57], \n",
    "        \"PureBreed\": [False, True, True, False, False, False, True, True, False, True],\n",
    "    },\n",
    ")\n",
    "convert(metadata_df,metadata_uri)\n",
    "\n",
    "query_parent = \"X400\"\n",
    "\n",
    "with tiledb.open(metadata_uri, \"r\") as Ar:\n",
    "    sample_result = Ar.query(cond=f\"Parent == '{query_parent}'\")[:]\n",
    "\n",
    "samples = [s.decode() for s in sample_result[\"Sample\"]]\n",
    "print(samples)\n",
    "variant_results = ds.read(\n",
    "#    regions=[\"1:10177-249240219\"],\n",
    "    samples=samples,\n",
    "    attrs=[\n",
    "        \"sample_name\",\n",
    "        \"contig\",\n",
    "        \"pos_start\",\n",
    "        \"pos_end\",\n",
    "        \"alleles\",\n",
    "        \"fmt_GT\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "variant_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa7456",
   "metadata": {},
   "source": [
    "# 4. Export a TileDB-VCF dataset instance to VCF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022e822",
   "metadata": {},
   "source": [
    "The contents of the TileDB arrays can be written to file using `ds.export`. Let's first investigate how to export the data to a VCF file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0aac0edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 55.8 ms, sys: 100 ms, total: 156 ms\n",
      "Wall time: 154 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.export(\n",
    "    regions = ['1:10177-24924'],\n",
    "    samples = ['HG00101'],\n",
    "    output_format = 'v',\n",
    "    output_dir = 'temp_VCF_exports/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e0ebf",
   "metadata": {},
   "source": [
    "Notice that it is possible to include slicing as part of the export option, such as genomic coordinates and samples. VCF files are plain files and can be opened in any editor. In the below example, the file is opened by `less`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8e81b1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.1\n",
      "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
      "##fileDate=20150218\n",
      "##reference=ftp://ftp.1000genomes.ebi.ac.uk//vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz\n",
      "##source=1000GenomesPhase3Pipeline\n",
      "##contig=<ID=1,assembly=b37,length=249250621>\n",
      "##contig=<ID=2,assembly=b37,length=243199373>\n",
      "##contig=<ID=3,assembly=b37,length=198022430>\n",
      "##contig=<ID=4,assembly=b37,length=191154276>\n",
      "##contig=<ID=5,assembly=b37,length=180915260>\n",
      "##contig=<ID=6,assembly=b37,length=171115067>\n",
      "##contig=<ID=7,assembly=b37,length=159138663>\n",
      "##contig=<ID=8,assembly=b37,length=146364022>\n",
      "##contig=<ID=9,assembly=b37,length=141213431>\n",
      "##contig=<ID=10,assembly=b37,length=135534747>\n",
      "##contig=<ID=11,assembly=b37,length=135006516>\n",
      "##contig=<ID=12,assembly=b37,length=133851895>\n",
      "##contig=<ID=13,assembly=b37,length=115169878>\n",
      "##contig=<ID=14,assembly=b37,length=107349540>\n",
      "##contig=<ID=15,assembly=b37,length=102531392>\n",
      "##contig=<ID=16,assembly=b37,length=90354753>\n",
      "##contig=<ID=17,assembly=b37,length=81195210>\n",
      "##contig=<ID=18,assembly=b37,length=78077248>\n",
      "##contig=<ID=19,assembly=b37,length=59128983>\n",
      "##contig=<ID=20,assembly=b37,length=63025520>\n",
      "##contig=<ID=21,assembly=b37,length=48129895>\n",
      "##contig=<ID=22,assembly=b37,length=51304566>\n",
      "##contig=<ID=GL000191.1,assembly=b37,length=106433>\n",
      "##contig=<ID=GL000192.1,assembly=b37,length=547496>\n",
      "##contig=<ID=GL000193.1,assembly=b37,length=189789>\n",
      "##contig=<ID=GL000194.1,assembly=b37,length=191469>\n",
      "##contig=<ID=GL000195.1,assembly=b37,length=182896>\n",
      "##contig=<ID=GL000196.1,assembly=b37,length=38914>\n",
      "##contig=<ID=GL000197.1,assembly=b37,length=37175>\n",
      "##contig=<ID=GL000198.1,assembly=b37,length=90085>\n",
      "##contig=<ID=GL000199.1,assembly=b37,length=169874>\n",
      "##contig=<ID=GL000200.1,assembly=b37,length=187035>\n",
      "##contig=<ID=GL000201.1,assembly=b37,length=36148>\n",
      "##contig=<ID=GL000202.1,assembly=b37,length=40103>\n",
      "##contig=<ID=GL000203.1,assembly=b37,length=37498>\n",
      "##contig=<ID=GL000204.1,assembly=b37,length=81310>\n",
      "##contig=<ID=GL000205.1,assembly=b37,length=174588>\n",
      "##contig=<ID=GL000206.1,assembly=b37,length=41001>\n",
      "##contig=<ID=GL000207.1,assembly=b37,length=4262>\n",
      "##contig=<ID=GL000208.1,assembly=b37,length=92689>\n",
      "##contig=<ID=GL000209.1,assembly=b37,length=159169>\n",
      "##contig=<ID=GL000210.1,assembly=b37,length=27682>\n",
      "##contig=<ID=GL000211.1,assembly=b37,length=166566>\n",
      "##contig=<ID=GL000212.1,assembly=b37,length=186858>\n",
      "##contig=<ID=GL000213.1,assembly=b37,length=164239>\n"
     ]
    }
   ],
   "source": [
    "!less ./temp_VCF_exports/HG00101.vcf | head -n 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07961da3",
   "metadata": {},
   "source": [
    "The possible export methods are described in the docstring below. \n",
    "\n",
    "The supported output formats are `'b': bcf (compressed), 'u': bcf, 'z':vcf.gz, 'v': vcf.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7ba1ea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method export in module tiledbvcf.dataset:\n",
      "\n",
      "export(samples: (<class 'str'>, typing.List[str]) = None, regions: (<class 'str'>, typing.List[str]) = None, samples_file: str = None, bed_file: str = None, skip_check_samples: bool = False, enable_progress_estimation: bool = False, merge: bool = False, output_format: str = 'z', output_path: str = '', output_dir: str = '.') method of tiledbvcf.dataset.Dataset instance\n",
      "    Exports data to multiple VCF files or a combined VCF file.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    samples\n",
      "        Sample names to be read.\n",
      "    regions\n",
      "        Genomic regions to be read.\n",
      "    samples_file\n",
      "        URI of file containing sample names to be read, one per line.\n",
      "    bed_file\n",
      "        URI of a BED file of genomic regions to be read.\n",
      "    skip_check_samples\n",
      "        Skip checking if the samples in `samples_file` exist in the dataset.\n",
      "    set_af_filter\n",
      "        Filter variants by internal allele frequency. For example, to include\n",
      "        variants with AF > 0.1, set this to \">0.1\".\n",
      "    scan_all_samples\n",
      "        Scan all samples when computing internal allele frequency.\n",
      "    enable_progress_estimation\n",
      "        **DEPRECATED** - This parameter will be removed in a future release.\n",
      "    merge\n",
      "        Merge samples to create a combined VCF file.\n",
      "    output_format\n",
      "        Export file format: 'b': bcf (compressed), 'u': bcf, 'z':vcf.gz, 'v': vcf.\n",
      "    output_path\n",
      "        Combined VCF output file.\n",
      "    output_dir\n",
      "        Directory used for local output of exported samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ds.export)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c2a86",
   "metadata": {},
   "source": [
    "VCF files can contain data from one sample, or data from multiple samples. Combining samples can for instance be done with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "77ab6e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.8 ms, sys: 95.3 ms, total: 148 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds.export(\n",
    "    regions = ['1:10177-24924'],\n",
    "    samples = ds.samples()[0:5],\n",
    "    merge = True,\n",
    "    output_format = 'v',\n",
    "    output_path = 'temp_VCF_exports/combined.vcf',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aad9a5",
   "metadata": {},
   "source": [
    "For the sake of variety, let's use `bcftools` to view this file. Calling on this or `vcftools` will be useful to perform benchmarking later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "362bac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.2\n",
      "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
      "##fileDate=20150218\n",
      "##reference=ftp://ftp.1000genomes.ebi.ac.uk//vol1/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz\n",
      "##source=1000GenomesPhase3Pipeline\n",
      "##contig=<ID=1,assembly=b37,length=249250621>\n",
      "##contig=<ID=2,assembly=b37,length=243199373>\n",
      "##contig=<ID=3,assembly=b37,length=198022430>\n",
      "##contig=<ID=4,assembly=b37,length=191154276>\n",
      "##contig=<ID=5,assembly=b37,length=180915260>\n",
      "##contig=<ID=6,assembly=b37,length=171115067>\n",
      "##contig=<ID=7,assembly=b37,length=159138663>\n",
      "##contig=<ID=8,assembly=b37,length=146364022>\n",
      "##contig=<ID=9,assembly=b37,length=141213431>\n",
      "##contig=<ID=10,assembly=b37,length=135534747>\n",
      "##contig=<ID=11,assembly=b37,length=135006516>\n",
      "##contig=<ID=12,assembly=b37,length=133851895>\n",
      "##contig=<ID=13,assembly=b37,length=115169878>\n",
      "##contig=<ID=14,assembly=b37,length=107349540>\n",
      "##contig=<ID=15,assembly=b37,length=102531392>\n",
      "##contig=<ID=16,assembly=b37,length=90354753>\n",
      "##contig=<ID=17,assembly=b37,length=81195210>\n",
      "##contig=<ID=18,assembly=b37,length=78077248>\n",
      "##contig=<ID=19,assembly=b37,length=59128983>\n",
      "##contig=<ID=20,assembly=b37,length=63025520>\n",
      "##contig=<ID=21,assembly=b37,length=48129895>\n",
      "##contig=<ID=22,assembly=b37,length=51304566>\n",
      "##contig=<ID=GL000191.1,assembly=b37,length=106433>\n",
      "##contig=<ID=GL000192.1,assembly=b37,length=547496>\n",
      "##contig=<ID=GL000193.1,assembly=b37,length=189789>\n",
      "##contig=<ID=GL000194.1,assembly=b37,length=191469>\n",
      "##contig=<ID=GL000195.1,assembly=b37,length=182896>\n",
      "##contig=<ID=GL000196.1,assembly=b37,length=38914>\n",
      "##contig=<ID=GL000197.1,assembly=b37,length=37175>\n",
      "##contig=<ID=GL000198.1,assembly=b37,length=90085>\n",
      "##contig=<ID=GL000199.1,assembly=b37,length=169874>\n",
      "##contig=<ID=GL000200.1,assembly=b37,length=187035>\n",
      "##contig=<ID=GL000201.1,assembly=b37,length=36148>\n",
      "##contig=<ID=GL000202.1,assembly=b37,length=40103>\n",
      "##contig=<ID=GL000203.1,assembly=b37,length=37498>\n",
      "##contig=<ID=GL000204.1,assembly=b37,length=81310>\n",
      "##contig=<ID=GL000205.1,assembly=b37,length=174588>\n",
      "##contig=<ID=GL000206.1,assembly=b37,length=41001>\n",
      "##contig=<ID=GL000207.1,assembly=b37,length=4262>\n",
      "##contig=<ID=GL000208.1,assembly=b37,length=92689>\n",
      "##contig=<ID=GL000209.1,assembly=b37,length=159169>\n",
      "##contig=<ID=GL000210.1,assembly=b37,length=27682>\n",
      "##contig=<ID=GL000211.1,assembly=b37,length=166566>\n",
      "##contig=<ID=GL000212.1,assembly=b37,length=186858>\n",
      "##contig=<ID=GL000213.1,assembly=b37,length=164239>\n",
      "##contig=<ID=GL000214.1,assembly=b37,length=137718>\n",
      "##contig=<ID=GL000215.1,assembly=b37,length=172545>\n",
      "##contig=<ID=GL000216.1,assembly=b37,length=172294>\n",
      "##contig=<ID=GL000217.1,assembly=b37,length=172149>\n",
      "##contig=<ID=GL000218.1,assembly=b37,length=161147>\n",
      "##contig=<ID=GL000219.1,assembly=b37,length=179198>\n",
      "##contig=<ID=GL000220.1,assembly=b37,length=161802>\n",
      "##contig=<ID=GL000221.1,assembly=b37,length=155397>\n",
      "##contig=<ID=GL000222.1,assembly=b37,length=186861>\n",
      "##contig=<ID=GL000223.1,assembly=b37,length=180455>\n",
      "##contig=<ID=GL000224.1,assembly=b37,length=179693>\n",
      "##contig=<ID=GL000225.1,assembly=b37,length=211173>\n",
      "##contig=<ID=GL000226.1,assembly=b37,length=15008>\n",
      "##contig=<ID=GL000227.1,assembly=b37,length=128374>\n",
      "##contig=<ID=GL000228.1,assembly=b37,length=129120>\n",
      "##contig=<ID=GL000229.1,assembly=b37,length=19913>\n",
      "##contig=<ID=GL000230.1,assembly=b37,length=43691>\n",
      "##contig=<ID=GL000231.1,assembly=b37,length=27386>\n",
      "##contig=<ID=GL000232.1,assembly=b37,length=40652>\n",
      "##contig=<ID=GL000233.1,assembly=b37,length=45941>\n",
      "##contig=<ID=GL000234.1,assembly=b37,length=40531>\n",
      "##contig=<ID=GL000235.1,assembly=b37,length=34474>\n",
      "##contig=<ID=GL000236.1,assembly=b37,length=41934>\n",
      "##contig=<ID=GL000237.1,assembly=b37,length=45867>\n",
      "##contig=<ID=GL000238.1,assembly=b37,length=39939>\n",
      "##contig=<ID=GL000239.1,assembly=b37,length=33824>\n",
      "##contig=<ID=GL000240.1,assembly=b37,length=41933>\n",
      "##contig=<ID=GL000241.1,assembly=b37,length=42152>\n",
      "##contig=<ID=GL000242.1,assembly=b37,length=43523>\n",
      "##contig=<ID=GL000243.1,assembly=b37,length=43341>\n",
      "##contig=<ID=GL000244.1,assembly=b37,length=39929>\n",
      "##contig=<ID=GL000245.1,assembly=b37,length=36651>\n",
      "##contig=<ID=GL000246.1,assembly=b37,length=38154>\n",
      "##contig=<ID=GL000247.1,assembly=b37,length=36422>\n",
      "##contig=<ID=GL000248.1,assembly=b37,length=39786>\n",
      "##contig=<ID=GL000249.1,assembly=b37,length=38502>\n",
      "##contig=<ID=MT,assembly=b37,length=16569>\n",
      "##contig=<ID=NC_007605,assembly=b37,length=171823>\n",
      "##contig=<ID=X,assembly=b37,length=155270560>\n",
      "##contig=<ID=Y,assembly=b37,length=59373566>\n",
      "##contig=<ID=hs37d5,assembly=b37,length=35477943>\n",
      "##ALT=<ID=CNV,Description=\"Copy Number Polymorphism\">\n",
      "##ALT=<ID=DEL,Description=\"Deletion\">\n",
      "##ALT=<ID=DUP,Description=\"Duplication\">\n",
      "##ALT=<ID=INS:ME:ALU,Description=\"Insertion of ALU element\">\n",
      "##ALT=<ID=INS:ME:LINE1,Description=\"Insertion of LINE1 element\">\n",
      "##ALT=<ID=INS:ME:SVA,Description=\"Insertion of SVA element\">\n",
      "##ALT=<ID=INS:MT,Description=\"Nuclear Mitochondrial Insertion\">\n",
      "##ALT=<ID=INV,Description=\"Inversion\">\n",
      "##ALT=<ID=CN0,Description=\"Copy number allele: 0 copies\">\n",
      "##ALT=<ID=CN1,Description=\"Copy number allele: 1 copy\">\n",
      "##ALT=<ID=CN2,Description=\"Copy number allele: 2 copies\">\n",
      "##ALT=<ID=CN3,Description=\"Copy number allele: 3 copies\">\n",
      "##ALT=<ID=CN4,Description=\"Copy number allele: 4 copies\">\n",
      "##ALT=<ID=CN5,Description=\"Copy number allele: 5 copies\">\n",
      "##ALT=<ID=CN6,Description=\"Copy number allele: 6 copies\">\n",
      "##ALT=<ID=CN7,Description=\"Copy number allele: 7 copies\">\n",
      "##ALT=<ID=CN8,Description=\"Copy number allele: 8 copies\">\n",
      "##ALT=<ID=CN9,Description=\"Copy number allele: 9 copies\">\n",
      "##ALT=<ID=CN10,Description=\"Copy number allele: 10 copies\">\n",
      "##ALT=<ID=CN11,Description=\"Copy number allele: 11 copies\">\n",
      "##ALT=<ID=CN12,Description=\"Copy number allele: 12 copies\">\n",
      "##ALT=<ID=CN13,Description=\"Copy number allele: 13 copies\">\n",
      "##ALT=<ID=CN14,Description=\"Copy number allele: 14 copies\">\n",
      "##ALT=<ID=CN15,Description=\"Copy number allele: 15 copies\">\n",
      "##ALT=<ID=CN16,Description=\"Copy number allele: 16 copies\">\n",
      "##ALT=<ID=CN17,Description=\"Copy number allele: 17 copies\">\n",
      "##ALT=<ID=CN18,Description=\"Copy number allele: 18 copies\">\n",
      "##ALT=<ID=CN19,Description=\"Copy number allele: 19 copies\">\n",
      "##ALT=<ID=CN20,Description=\"Copy number allele: 20 copies\">\n",
      "##ALT=<ID=CN21,Description=\"Copy number allele: 21 copies\">\n",
      "##ALT=<ID=CN22,Description=\"Copy number allele: 22 copies\">\n",
      "##ALT=<ID=CN23,Description=\"Copy number allele: 23 copies\">\n",
      "##ALT=<ID=CN24,Description=\"Copy number allele: 24 copies\">\n",
      "##ALT=<ID=CN25,Description=\"Copy number allele: 25 copies\">\n",
      "##ALT=<ID=CN26,Description=\"Copy number allele: 26 copies\">\n",
      "##ALT=<ID=CN27,Description=\"Copy number allele: 27 copies\">\n",
      "##ALT=<ID=CN28,Description=\"Copy number allele: 28 copies\">\n",
      "##ALT=<ID=CN29,Description=\"Copy number allele: 29 copies\">\n",
      "##ALT=<ID=CN30,Description=\"Copy number allele: 30 copies\">\n",
      "##ALT=<ID=CN31,Description=\"Copy number allele: 31 copies\">\n",
      "##ALT=<ID=CN32,Description=\"Copy number allele: 32 copies\">\n",
      "##ALT=<ID=CN33,Description=\"Copy number allele: 33 copies\">\n",
      "##ALT=<ID=CN34,Description=\"Copy number allele: 34 copies\">\n",
      "##ALT=<ID=CN35,Description=\"Copy number allele: 35 copies\">\n",
      "##ALT=<ID=CN36,Description=\"Copy number allele: 36 copies\">\n",
      "##ALT=<ID=CN37,Description=\"Copy number allele: 37 copies\">\n",
      "##ALT=<ID=CN38,Description=\"Copy number allele: 38 copies\">\n",
      "##ALT=<ID=CN39,Description=\"Copy number allele: 39 copies\">\n",
      "##ALT=<ID=CN40,Description=\"Copy number allele: 40 copies\">\n",
      "##ALT=<ID=CN41,Description=\"Copy number allele: 41 copies\">\n",
      "##ALT=<ID=CN42,Description=\"Copy number allele: 42 copies\">\n",
      "##ALT=<ID=CN43,Description=\"Copy number allele: 43 copies\">\n",
      "##ALT=<ID=CN44,Description=\"Copy number allele: 44 copies\">\n",
      "##ALT=<ID=CN45,Description=\"Copy number allele: 45 copies\">\n",
      "##ALT=<ID=CN46,Description=\"Copy number allele: 46 copies\">\n",
      "##ALT=<ID=CN47,Description=\"Copy number allele: 47 copies\">\n",
      "##ALT=<ID=CN48,Description=\"Copy number allele: 48 copies\">\n",
      "##ALT=<ID=CN49,Description=\"Copy number allele: 49 copies\">\n",
      "##ALT=<ID=CN50,Description=\"Copy number allele: 50 copies\">\n",
      "##ALT=<ID=CN51,Description=\"Copy number allele: 51 copies\">\n",
      "##ALT=<ID=CN52,Description=\"Copy number allele: 52 copies\">\n",
      "##ALT=<ID=CN53,Description=\"Copy number allele: 53 copies\">\n",
      "##ALT=<ID=CN54,Description=\"Copy number allele: 54 copies\">\n",
      "##ALT=<ID=CN55,Description=\"Copy number allele: 55 copies\">\n",
      "##ALT=<ID=CN56,Description=\"Copy number allele: 56 copies\">\n",
      "##ALT=<ID=CN57,Description=\"Copy number allele: 57 copies\">\n",
      "##ALT=<ID=CN58,Description=\"Copy number allele: 58 copies\">\n",
      "##ALT=<ID=CN59,Description=\"Copy number allele: 59 copies\">\n",
      "##ALT=<ID=CN60,Description=\"Copy number allele: 60 copies\">\n",
      "##ALT=<ID=CN61,Description=\"Copy number allele: 61 copies\">\n",
      "##ALT=<ID=CN62,Description=\"Copy number allele: 62 copies\">\n",
      "##ALT=<ID=CN63,Description=\"Copy number allele: 63 copies\">\n",
      "##ALT=<ID=CN64,Description=\"Copy number allele: 64 copies\">\n",
      "##ALT=<ID=CN65,Description=\"Copy number allele: 65 copies\">\n",
      "##ALT=<ID=CN66,Description=\"Copy number allele: 66 copies\">\n",
      "##ALT=<ID=CN67,Description=\"Copy number allele: 67 copies\">\n",
      "##ALT=<ID=CN68,Description=\"Copy number allele: 68 copies\">\n",
      "##ALT=<ID=CN69,Description=\"Copy number allele: 69 copies\">\n",
      "##ALT=<ID=CN70,Description=\"Copy number allele: 70 copies\">\n",
      "##ALT=<ID=CN71,Description=\"Copy number allele: 71 copies\">\n",
      "##ALT=<ID=CN72,Description=\"Copy number allele: 72 copies\">\n",
      "##ALT=<ID=CN73,Description=\"Copy number allele: 73 copies\">\n",
      "##ALT=<ID=CN74,Description=\"Copy number allele: 74 copies\">\n",
      "##ALT=<ID=CN75,Description=\"Copy number allele: 75 copies\">\n",
      "##ALT=<ID=CN76,Description=\"Copy number allele: 76 copies\">\n",
      "##ALT=<ID=CN77,Description=\"Copy number allele: 77 copies\">\n",
      "##ALT=<ID=CN78,Description=\"Copy number allele: 78 copies\">\n",
      "##ALT=<ID=CN79,Description=\"Copy number allele: 79 copies\">\n",
      "##ALT=<ID=CN80,Description=\"Copy number allele: 80 copies\">\n",
      "##ALT=<ID=CN81,Description=\"Copy number allele: 81 copies\">\n",
      "##ALT=<ID=CN82,Description=\"Copy number allele: 82 copies\">\n",
      "##ALT=<ID=CN83,Description=\"Copy number allele: 83 copies\">\n",
      "##ALT=<ID=CN84,Description=\"Copy number allele: 84 copies\">\n",
      "##ALT=<ID=CN85,Description=\"Copy number allele: 85 copies\">\n",
      "##ALT=<ID=CN86,Description=\"Copy number allele: 86 copies\">\n",
      "##ALT=<ID=CN87,Description=\"Copy number allele: 87 copies\">\n",
      "##ALT=<ID=CN88,Description=\"Copy number allele: 88 copies\">\n",
      "##ALT=<ID=CN89,Description=\"Copy number allele: 89 copies\">\n",
      "##ALT=<ID=CN90,Description=\"Copy number allele: 90 copies\">\n",
      "##ALT=<ID=CN91,Description=\"Copy number allele: 91 copies\">\n",
      "##ALT=<ID=CN92,Description=\"Copy number allele: 92 copies\">\n",
      "##ALT=<ID=CN93,Description=\"Copy number allele: 93 copies\">\n",
      "##ALT=<ID=CN94,Description=\"Copy number allele: 94 copies\">\n",
      "##ALT=<ID=CN95,Description=\"Copy number allele: 95 copies\">\n",
      "##ALT=<ID=CN96,Description=\"Copy number allele: 96 copies\">\n",
      "##ALT=<ID=CN97,Description=\"Copy number allele: 97 copies\">\n",
      "##ALT=<ID=CN98,Description=\"Copy number allele: 98 copies\">\n",
      "##ALT=<ID=CN99,Description=\"Copy number allele: 99 copies\">\n",
      "##ALT=<ID=CN100,Description=\"Copy number allele: 100 copies\">\n",
      "##ALT=<ID=CN101,Description=\"Copy number allele: 101 copies\">\n",
      "##ALT=<ID=CN102,Description=\"Copy number allele: 102 copies\">\n",
      "##ALT=<ID=CN103,Description=\"Copy number allele: 103 copies\">\n",
      "##ALT=<ID=CN104,Description=\"Copy number allele: 104 copies\">\n",
      "##ALT=<ID=CN105,Description=\"Copy number allele: 105 copies\">\n",
      "##ALT=<ID=CN106,Description=\"Copy number allele: 106 copies\">\n",
      "##ALT=<ID=CN107,Description=\"Copy number allele: 107 copies\">\n",
      "##ALT=<ID=CN108,Description=\"Copy number allele: 108 copies\">\n",
      "##ALT=<ID=CN109,Description=\"Copy number allele: 109 copies\">\n",
      "##ALT=<ID=CN110,Description=\"Copy number allele: 110 copies\">\n",
      "##ALT=<ID=CN111,Description=\"Copy number allele: 111 copies\">\n",
      "##ALT=<ID=CN112,Description=\"Copy number allele: 112 copies\">\n",
      "##ALT=<ID=CN113,Description=\"Copy number allele: 113 copies\">\n",
      "##ALT=<ID=CN114,Description=\"Copy number allele: 114 copies\">\n",
      "##ALT=<ID=CN115,Description=\"Copy number allele: 115 copies\">\n",
      "##ALT=<ID=CN116,Description=\"Copy number allele: 116 copies\">\n",
      "##ALT=<ID=CN117,Description=\"Copy number allele: 117 copies\">\n",
      "##ALT=<ID=CN118,Description=\"Copy number allele: 118 copies\">\n",
      "##ALT=<ID=CN119,Description=\"Copy number allele: 119 copies\">\n",
      "##ALT=<ID=CN120,Description=\"Copy number allele: 120 copies\">\n",
      "##ALT=<ID=CN121,Description=\"Copy number allele: 121 copies\">\n",
      "##ALT=<ID=CN122,Description=\"Copy number allele: 122 copies\">\n",
      "##ALT=<ID=CN123,Description=\"Copy number allele: 123 copies\">\n",
      "##ALT=<ID=CN124,Description=\"Copy number allele: 124 copies\">\n",
      "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">\n",
      "##INFO=<ID=CIEND,Number=2,Type=Integer,Description=\"Confidence interval around END for imprecise variants\">\n",
      "##INFO=<ID=CIPOS,Number=2,Type=Integer,Description=\"Confidence interval around POS for imprecise variants\">\n",
      "##INFO=<ID=CS,Number=1,Type=String,Description=\"Source call set.\">\n",
      "##INFO=<ID=END,Number=1,Type=Integer,Description=\"End coordinate of this variant\">\n",
      "##INFO=<ID=IMPRECISE,Number=0,Type=Flag,Description=\"Imprecise structural variation\">\n",
      "##INFO=<ID=MC,Number=.,Type=String,Description=\"Merged calls.\">\n",
      "##INFO=<ID=MEINFO,Number=4,Type=String,Description=\"Mobile element info of the form NAME,START,END<POLARITY; If there is only 5' OR 3' support for this call, will be NULL NULL for START and END\">\n",
      "##INFO=<ID=MEND,Number=1,Type=Integer,Description=\"Mitochondrial end coordinate of inserted sequence\">\n",
      "##INFO=<ID=MLEN,Number=1,Type=Integer,Description=\"Estimated length of mitochondrial insert\">\n",
      "##INFO=<ID=MSTART,Number=1,Type=Integer,Description=\"Mitochondrial start coordinate of inserted sequence\">\n",
      "##INFO=<ID=SVLEN,Number=.,Type=Integer,Description=\"SV length. It is only calculated for structural variation MEIs. For other types of SVs; one may calculate the SV length by INFO:END-START+1, or by finding the difference between lengthes of REF and ALT alleles\">\n",
      "##INFO=<ID=SVTYPE,Number=1,Type=String,Description=\"Type of structural variant\">\n",
      "##INFO=<ID=TSD,Number=1,Type=String,Description=\"Precise Target Site Duplication for bases, if unknown, value will be NULL\">\n",
      "##INFO=<ID=AC,Number=A,Type=Integer,Description=\"Total number of alternate alleles in called genotypes\">\n",
      "##INFO=<ID=AN,Number=1,Type=Integer,Description=\"Total number of alleles in called genotypes\">\n",
      "##INFO=<ID=DP,Number=1,Type=Integer,Description=\"Total read depth; only low coverage data were counted towards the DP, exome data were not used\">\n",
      "##INFO=<ID=AA,Number=1,Type=String,Description=\"Ancestral Allele. Format: AA|REF|ALT|IndelType. AA: Ancestral allele, REF:Reference Allele, ALT:Alternate Allele, IndelType:Type of Indel (REF, ALT and IndelType are only defined for indels)\">\n",
      "##INFO=<ID=VT,Number=.,Type=String,Description=\"indicates what type of variant the line represents\">\n",
      "##INFO=<ID=EX_TARGET,Number=0,Type=Flag,Description=\"indicates whether a variant is within the exon pull down target boundaries\">\n",
      "##INFO=<ID=MULTI_ALLELIC,Number=0,Type=Flag,Description=\"indicates whether a site is multi-allelic\">\n",
      "##bcftools_viewVersion=1.10.2+htslib-1.10.2\n",
      "##bcftools_viewCommand=view --min-ac 1 -Ou -s HG00096 data/split-bcfs/HG00096.bcf; Date=Tue Dec 29 20:02:46 2020\n",
      "##bcftools_annotateVersion=1.10.2+htslib-1.10.2\n",
      "##bcftools_annotateCommand=annotate -Ob --remove INFO/AF,INFO/NS,INFO/EAS_AF,INFO/AMR_AF,INFO/AFR_AF,INFO/EUR_AF,INFO/SAS_AF -o data/filtered-bcfs/HG00096.bcf; Date=Tue Dec 29 20:02:46 2020\n",
      "##bcftools_viewVersion=1.20+htslib-1.20\n",
      "##bcftools_viewCommand=view ./temp_VCF_exports/combined.vcf; Date=Fri Dec 13 13:04:33 2024\n",
      "#CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO\tFORMAT\tHG00096\tHG00097\tHG00099\tHG00100\tHG00101\n",
      "1\t10177\trs367896724\tA\tAC\t100\tPASS\tDP=412608;VT=INDEL;AA=|||unknown(NO_COVERAGE);AC=4;AN=8;END=10177\tGT\t1|0\t0|1\t0|1\t1|0\t./.\n",
      "1\t10352\trs555500075\tT\tTA\t100\tPASS\tDP=444575;VT=INDEL;AA=|||unknown(NO_COVERAGE);AC=5;AN=10;END=10352\tGT\t1|0\t1|0\t0|1\t0|1\t1|0\n",
      "1\t10616\trs376342519\tCCGCCGTTGCAAAGGCGCGCCG\tC\t100\tPASS\tDP=11825;VT=INDEL;AC=10;AN=10;END=10637\tGT\t1|1\t1|1\t1|1\t1|1\t1|1\n",
      "1\t13110\trs540538026\tG\tA\t100\tPASS\tDP=23422;VT=SNP;AA=g|||;AC=1;AN=2;END=13110\tGT\t./.\t1|0\t./.\t./.\t./.\n",
      "1\t13116\trs62635286\tT\tG\t100\tPASS\tDP=44680;VT=SNP;AA=t|||;AC=2;AN=4;END=13116\tGT\t./.\t1|0\t./.\t./.\t1|0\n",
      "1\t13118\trs200579949\tA\tG\t100\tPASS\tDP=42790;VT=SNP;AA=a|||;AC=2;AN=4;END=13118\tGT\t./.\t1|0\t./.\t./.\t1|0\n",
      "1\t14464\trs546169444\tA\tT\t100\tPASS\tDP=53522;VT=SNP;AA=a|||;AC=3;AN=4;END=14464\tGT\t1|1\t./.\t1|0\t./.\t./.\n",
      "1\t14599\trs531646671\tT\tA\t100\tPASS\tDP=64162;VT=SNP;AA=t|||;AC=2;AN=4;END=14599\tGT\t./.\t0|1\t1|0\t./.\t./.\n",
      "1\t14604\trs541940975\tA\tG\t100\tPASS\tDP=58462;VT=SNP;AA=a|||;AC=2;AN=4;END=14604\tGT\t./.\t0|1\t1|0\t./.\t./.\n",
      "1\t14930\trs75454623\tA\tG\t100\tPASS\tDP=211155;VT=SNP;AA=a|||;AC=5;AN=10;END=14930\tGT\t1|0\t0|1\t0|1\t1|0\t1|0\n",
      "1\t15211\trs78601809\tT\tG\t100\tPASS\tDP=161225;VT=SNP;AA=t|||;AC=5;AN=10;END=15211\tGT\t0|1\t0|1\t0|1\t0|1\t1|0\n",
      "1\t15274\trs62636497\tA\tG,T\t100\tPASS\tDP=116275;MULTI_ALLELIC;VT=SNP;AA=g|||;AC=3,7;AN=10;END=15274\tGT\t1|2\t2|2\t2|2\t1|2\t1|2\n",
      "1\t15820\trs2691315\tG\tT\t100\tPASS\tDP=44799;VT=SNP;AA=t|||;AC=3;EX_TARGET;AN=6;END=15820\tGT\t1|0\t0|1\t0|1\t./.\t./.\n",
      "1\t15903\trs557514207\tG\tGC\t100\tPASS\tDP=28048;VT=INDEL;AA=ccc|CC|CCC|deletion;AC=4;EX_TARGET;AN=8;END=15903\tGT\t0|1\t0|1\t./.\t1|0\t0|1\n",
      "1\t16949\trs199745162\tA\tC\t100\tPASS\tDP=83348;VT=SNP;AA=a|||;AC=2;EX_TARGET;AN=4;END=16949\tGT\t./.\t./.\t0|1\t./.\t0|1\n",
      "1\t18643\trs564023708\tG\tA\t100\tPASS\tDP=42848;VT=SNP;AA=g|||;AC=1;AN=2;END=18643\tGT\t./.\t./.\t1|0\t./.\t./.\n",
      "1\t18849\trs533090414\tC\tG\t100\tPASS\tDP=23500;VT=SNP;AA=g|||;AC=10;AN=10;END=18849\tGT\t1|1\t1|1\t1|1\t1|1\t1|1\n"
     ]
    }
   ],
   "source": [
    "!bcftools view ./temp_VCF_exports/combined.vcf | head -1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b975335",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
